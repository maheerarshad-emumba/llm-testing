{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.metrics.genai import make_genai_metric, EvaluationExample\n",
    "import pandas as pd\n",
    "from mlflow.metrics.genai import make_genai_metric_from_prompt, EvaluationExample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv(\"C:/Users/Emumba/Documents/genie research/llm-testing-main/llm-testing-main/hallucination/llm_responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.metrics.genai import EvaluationExample\n",
    "\n",
    "# Example for \"Accurate\" response\n",
    "example_accurate = EvaluationExample(\n",
    "    input=\"What is MLflow?\",\n",
    "    output=\"MLflow is an open-source platform for managing the end-to-end machine learning lifecycle.\",\n",
    "    score=1,\n",
    "    justification=\"The response is fully accurate and answers the question based on the provided context and ground truth.\"\n",
    ")\n",
    "\n",
    "# Example for \"Minor Additional Detail\"\n",
    "example_minor_additional = EvaluationExample(\n",
    "    input=\"Who developed MLflow?\",\n",
    "    output=\"MLflow was developed by Databricks, with significant contributions from open-source collaborators.\",\n",
    "    score=2,\n",
    "    justification=\"The response is accurate but includes additional context about 'open-source collaborators' that is reasonable but not explicitly mentioned in the ground truth.\"\n",
    ")\n",
    "\n",
    "# Example for \"Contextually Relevant but Off-Topic\"\n",
    "example_contextually_relevant = EvaluationExample(\n",
    "    input=\"What is MLflow?\",\n",
    "    output=\"MLflow is designed for tracking and managing machine learning experiments.\",\n",
    "    score=3,\n",
    "    justification=\"The response is contextually relevant and grounded in the provided information, but it does not directly answer the question about MLflow's general purpose.\"\n",
    ")\n",
    "\n",
    "# Example for \"Hallucination\"\n",
    "example_hallucinated = EvaluationExample(\n",
    "    input=\"Explain MLflow's tracking feature.\",\n",
    "    output=\"MLflow's tracking feature lets users track their fitness activities and health data.\",\n",
    "    score=4,\n",
    "    justification=\"The response introduces unrelated information about tracking fitness and health data, which is not present in the ground truth or context, making it a hallucination.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_metric = make_genai_metric(\n",
    "    name=\"hallucination_evaluation\",\n",
    "    definition=(\n",
    "        \"This metric evaluates the hallucination level of the response. Responses are scored based on whether \"\n",
    "        \"they are grounded in context, include minor additional info, contain irrelevant details, or are hallucinated.\"\n",
    "    ),\n",
    "    grading_prompt=(\n",
    "        \"Hallucination Score: Evaluate the response and label it with one of the following descriptions:\\n\"\n",
    "        \"- Score 1: If the response accurately answers the question based on the provided ground truth and context, mark it as 'Accurate'.\\n\"\n",
    "        \"- Score 2: If the response is correct but includes minor details that are reasonable but not explicitly in the ground truth or context, mark it as 'Minor Additional Detail.'\\n\"\n",
    "        \"- Score 3: If the response is grounded in the context or ground truth but does not directly answer the question, mark it as 'Contextually Relevant but Off-Topic.'\\n\"\n",
    "        \"- Score 4: If the response introduces fabricated or unverified information that is not present in the ground truth or context, mark it as 'Hallucination.'\\n\"\n",
    "    ),\n",
    "    examples=[example_accurate, example_minor_additional, example_contextually_relevant, example_hallucinated],\n",
    "    model=\"openai:/gpt-4\",  # Replace with the LLM endpoint you’re using\n",
    "    parameters={\"temperature\": 0.0},\n",
    "    aggregations=[\"mean\"],\n",
    "    greater_is_better=False,\n",
    "    grading_context_columns=[\"context\"]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hallucination_with_labels(eval_data):\n",
    "    results = []\n",
    "    for _, row in eval_data.iterrows():\n",
    "        evaluation = hallucination_metric.evaluate(\n",
    "            input=row['query'],\n",
    "            output=row['response'],\n",
    "            context=row['context']\n",
    "        )\n",
    "        \n",
    "        # Collect results with descriptive labels\n",
    "        results.append({\n",
    "            \"query\": row['query'],\n",
    "            \"response\": row['response'],\n",
    "            \"ground_truth\": row['ground truth'],\n",
    "            \"hallucination_score\": evaluation.score,\n",
    "            \"hallucination_label\": evaluation.justification  # This will store the label (e.g., \"Minor Additional Info\")\n",
    "        })\n",
    "    \n",
    "    # Convert results to DataFrame for easier saving\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/06 16:04:15 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.25s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9471, Requested 2296. Please try again in 10.602s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9469, Requested 2157. Please try again in 9.756s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9467, Requested 2311. Please try again in 10.668s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9466, Requested 2346. Please try again in 10.872s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9466, Requested 2590. Please try again in 12.336s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9414, Requested 2564. Please try again in 11.868s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9410, Requested 2561. Please try again in 11.826s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9378, Requested 2311. Please try again in 10.134s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9375, Requested 2346. Please try again in 10.326s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9365, Requested 2590. Please try again in 11.73s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9320, Requested 2296. Please try again in 9.696s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9318, Requested 2561. Please try again in 11.274s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9317, Requested 2157. Please try again in 8.844s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9314, Requested 2564. Please try again in 11.268s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      " 20%|██        | 2/10 [00:03<00:12,  1.50s/it]WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8454, Requested 2346. Please try again in 4.8s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8456, Requested 2157. Please try again in 3.678s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8442, Requested 2561. Please try again in 6.018s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8419, Requested 2564. Please try again in 5.898s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8416, Requested 2311. Please try again in 4.362s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8414, Requested 2296. Please try again in 4.26s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8346, Requested 2296. Please try again in 3.851s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8346, Requested 2346. Please try again in 4.152s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8341, Requested 2157. Please try again in 2.988s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8305, Requested 2311. Please try again in 3.696s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8305, Requested 2564. Please try again in 5.214s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8305, Requested 2561. Please try again in 5.196s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      " 40%|████      | 4/10 [00:18<00:32,  5.41s/it]WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 7820, Requested 2561. Please try again in 2.286s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9960, Requested 2311. Please try again in 13.626s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9957, Requested 2296. Please try again in 13.518s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9958, Requested 2564. Please try again in 15.131s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9867, Requested 2296. Please try again in 12.978s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9852, Requested 2311. Please try again in 12.978s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9850, Requested 2561. Please try again in 14.466s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9849, Requested 2564. Please try again in 14.478s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      " 60%|██████    | 6/10 [00:35<00:24,  6.18s/it]WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9241, Requested 2564. Please try again in 10.83s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9239, Requested 2311. Please try again in 9.3s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9183, Requested 2296. Please try again in 8.874s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9129, Requested 2564. Please try again in 10.158s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9129, Requested 2311. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 9093, Requested 2296. Please try again in 8.334s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      " 70%|███████   | 7/10 [00:50<00:26,  9.00s/it]WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8754, Requested 2311. Please try again in 6.39s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "2024/11/06 16:05:22 WARNING mlflow.openai.api_request_parallel_processor: Retrying for request failed with rate limit.\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8691, Requested 2296. Please try again in 5.922s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "2024/11/06 16:05:22 WARNING mlflow.openai.api_request_parallel_processor: Retrying for request failed with rate limit.\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8638, Requested 2311. Please try again in 5.694s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      " 80%|████████  | 8/10 [01:06<00:21, 10.94s/it]WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 8059, Requested 2296. Please try again in 2.13s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "WARNING:root:Request #0 failed with error {'message': 'Rate limit reached for gpt-4 in organization org-2KghpaBYFpdnBkUzafFFUpOL on tokens per min (TPM): Limit 10000, Used 7896, Requested 2296. Please try again in 1.152s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}\n",
      "100%|██████████| 10/10 [01:38<00:00,  9.80s/it]\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 333.54it/s]\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 499.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               query  \\\n",
      "0  Does GTE-Large support up to 8192 tokens in a ...   \n",
      "1  Is BGE-M3 primarily used for summarization tasks?   \n",
      "2  Does GTE-Qwen2-7B-instruct provide specialized...   \n",
      "3  Which model between GTE-Base and GTE-Large per...   \n",
      "4  Does Recursive Retrieval allow token inputs ov...   \n",
      "5  Is there any embedding model specifically desi...   \n",
      "6  Does the GTE-Qwen2-7B-instruct model have real...   \n",
      "7  Can Recursive Retrieval merge results from mul...   \n",
      "8  Does BGE-M3 outperform GTE-Qwen2-7B-instruct o...   \n",
      "9  Are the Longformer Base 4096 and GTE-Large mod...   \n",
      "\n",
      "                                             context  \\\n",
      "0  Open Source Embedding Models GTE-Base General ...   \n",
      "1  Open Source Embedding Models GTE-Base General ...   \n",
      "2  It can simultaneously perform the three common...   \n",
      "3  Open Source Embedding Models GTE-Base General ...   \n",
      "4  both gave us quite good results! Sentence Wind...   \n",
      "5  for general text blobs Limited to 512 tokens E...   \n",
      "6  It can simultaneously perform the three common...   \n",
      "7  both gave us quite good results! Sentence Wind...   \n",
      "8  It can simultaneously perform the three common...   \n",
      "9  Open Source Embedding Models GTE-Base General ...   \n",
      "\n",
      "                                        ground truth  \\\n",
      "0             No, GTE Large supports upto 512 tokens   \n",
      "1             No such information present in context   \n",
      "2             No such information present in context   \n",
      "3             No such information present in context   \n",
      "4             No such information present in context   \n",
      "5             No such information present in context   \n",
      "6             No such information present in context   \n",
      "7             No such information present in context   \n",
      "8  It isn't specifically stated if BGE-M3 outperf...   \n",
      "9             No such information present in context   \n",
      "\n",
      "                                            response  \\\n",
      "0  No, GTE-Large does not support up to 8192 toke...   \n",
      "1  The provided context does not mention a model ...   \n",
      "2  The provided context does not mention anything...   \n",
      "3  The provided context does not include specific...   \n",
      "4  The provided context does not specify whether ...   \n",
      "5  The provided context does not mention any embe...   \n",
      "6  The context does not provide specific informat...   \n",
      "7  The context does not provide information on wh...   \n",
      "8  The context does not provide a direct comparis...   \n",
      "9  The provided context does not mention or imply...   \n",
      "\n",
      "   hallucination_evaluation/v1/score  \\\n",
      "0                                  1   \n",
      "1                                  1   \n",
      "2                                  1   \n",
      "3                                  1   \n",
      "4                                  4   \n",
      "5                                  4   \n",
      "6                                  3   \n",
      "7                                  3   \n",
      "8                                  1   \n",
      "9                                  1   \n",
      "\n",
      "           hallucination_evaluation/v1/justification  \n",
      "0  The response accurately answers the question b...  \n",
      "1  The response accurately answers the question b...  \n",
      "2  The response accurately answers the question b...  \n",
      "3  The model's response is accurate and directly ...  \n",
      "4  The model's response introduces information ab...  \n",
      "5  The model's response introduces fabricated inf...  \n",
      "6  The response is grounded in the context provid...  \n",
      "7  The response is grounded in the context and gr...  \n",
      "8  The response accurately answers the question b...  \n",
      "9  The response accurately answers the question b...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    # Run evaluation with mlflow.evaluate() instead of calling .evaluate() directly\n",
    "    results = mlflow.evaluate(\n",
    "        data=eval_df,\n",
    "        evaluators=\"default\",\n",
    "        targets=\"ground truth\",  # Column containing ground truth labels\n",
    "        predictions=\"response\",  # Column containing model responses\n",
    "        extra_metrics=[hallucination_metric],  # Include the custom hallucination metric\n",
    "        evaluator_config={\n",
    "            \"col_mapping\": {\n",
    "                \"inputs\": \"query\",\n",
    "                \"context\": \"context\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Log the hallucination results table as an artifact for detailed inspection\n",
    "    results_df = results.tables[\"eval_results_table\"]\n",
    "    output_file = \"hallucination_evaluation_with_labels.csv\"\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    mlflow.log_artifact(output_file)\n",
    "\n",
    "# Display results for verification\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
